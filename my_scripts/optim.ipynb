{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterCatalogEntry> already registered; second conversion method ignored.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "# for linux env.\n",
    "sys.path.insert(0,'..')\n",
    "import argparse\n",
    "# from distutils.util import strtobool\n",
    "import json\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# import networkx as nx\n",
    "# from rdkit import Chem, DataStructs\n",
    "# from rdkit.Chem import AllChem\n",
    "from copy import deepcopy\n",
    "# from mflow.generate import generate_mols_along_axis\n",
    "from dataloader import PretrainDataset\n",
    "from models.MolHF import MolHF\n",
    "from torch.utils.data import DataLoader\n",
    "# from envs import environment as env\n",
    "# from envs.timereport import TimeReport\n",
    "# from envs.environment import penalized_logp, qed \n",
    "# from utils import check_validity, adj_to_smiles, smiles_to_adj, construct_mol\n",
    "from multiprocessing import Pool\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error\n",
    "# from dataloader import get_mol_data\n",
    "from time import time, ctime\n",
    "# import functools\n",
    "import optimize_property as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобученная модель для оптимизации\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "#общие параметры\n",
    "parser.dataset = 'zinc250k' \n",
    "parser.device = 'cpu' \n",
    "parser.seed = 42\n",
    "parser.save = True\n",
    "parser.model = 'MolHF'\n",
    "parser.order = 'bfs'\n",
    "parser.property_name = 'plogp'\n",
    "\n",
    "parser.init_checkpoint = './save_pretrain/zinc250k_model/checkpoint.pth'\n",
    "parser.model_dir = './save_optimization'\n",
    "parser.property_model_path = 'plogp_moflow_zinc250k_10.pth'\n",
    "\n",
    "# параметры модели\n",
    "parser.deq_scale = 0.6 \n",
    "parser.batch_size = 256\n",
    "parser.lr = 1e-3 \n",
    "parser.squeeze_fold = 2 \n",
    "parser.n_block = 4 \n",
    "parser.a_num_flows = 6 \n",
    "parser.num_layers = 2 \n",
    "parser.hid_dim = 256 \n",
    "parser.b_num_flows = 3 \n",
    "parser.filter_size = 256 \n",
    "parser.temperature = 0.6 \n",
    "parser.learn_prior = True \n",
    "parser.inv_conv = True \n",
    "parser.inv_rotate = True \n",
    "parser.condition = True\n",
    "parser.hidden = '32'\n",
    "\n",
    "parser.num_data = None\n",
    "parser.is_test_idx = False\n",
    "parser.num_workers = 0\n",
    "parser.deq_type = 'random'\n",
    "parser.debug = 'true'\n",
    "\n",
    "# опциональные параметры для оптимизации\n",
    "parser.split = 'moflow'\n",
    "parser.topk = 30 \n",
    "parser.num_iter = 10 \n",
    "parser.opt_lr = 0.5\n",
    "parser.topscore = False\n",
    "parser.consopt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at Time: Tue Mar 25 14:23:03 2025\n",
      "reading data from ./data_preprocessed/zinc250k\n",
      "Atom order: bfs\n",
      "Hidden dim for output regression:  [32]\n",
      "Loading trained regression model for optimization\n",
      "Prepare data done! Time 5.57 seconds\n",
      "Load ./data_preprocessed/zinc250k/zinc250k_property.csv done, length: 249456\n",
      "loading plogp regression model from: ./save_optimization\\plogp_moflow_zinc250k_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Makss\\Documents\\Учёба\\Диплом\\NF_mol_gen\\optimize_property.py:544: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.init_checkpoint, map_location=args.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize from ./save_pretrain/zinc250k_model/checkpoint.pth Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Makss\\AppData\\Local\\Temp\\ipykernel_17512\\4208044209.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  property_model.load_state_dict(torch.load(property_model_path, map_location=args.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model done! Time 9.66 seconds\n",
      "Constrained optimization:\n",
      "Constrained optimization of plogp score\n",
      "the number of molecue is 0\n",
      "Optimization 0/30, time: 0.16 seconds\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mconsopt:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConstrained optimization:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstrain_optimization_smiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_prop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_test_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_prop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Time \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time() \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[1;32mc:\\Users\\Makss\\Documents\\Учёба\\Диплом\\NF_mol_gen\\optimize_property.py:519\u001b[0m, in \u001b[0;36mconstrain_optimization_smiles\u001b[1;34m(property_model, train_prop, data_config, args)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptimization \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, time: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i, args\u001b[38;5;241m.\u001b[39mtopk, time() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[0;32m    518\u001b[0m qed, plogp, smile \u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m--> 519\u001b[0m results, ori \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_mol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results)):\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results[t]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Makss\\Documents\\Учёба\\Диплом\\NF_mol_gen\\optimize_property.py:265\u001b[0m, in \u001b[0;36moptimize_mol\u001b[1;34m(property_model, smiles, data_config, args, random)\u001b[0m\n\u001b[0;32m    263\u001b[0m h \u001b[38;5;241m=\u001b[39m property_model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto_latent_format(mol_z)\n\u001b[0;32m    264\u001b[0m x_rev, adj_rev \u001b[38;5;241m=\u001b[39m property_model\u001b[38;5;241m.\u001b[39mreverse(h)\n\u001b[1;32m--> 265\u001b[0m reverse_smiles \u001b[38;5;241m=\u001b[39m \u001b[43madj_to_smiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_rev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_rev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum2atom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matom_valency\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28mprint\u001b[39m(smiles, reverse_smiles)\n\u001b[0;32m    267\u001b[0m z, _, _,  \u001b[38;5;241m=\u001b[39m property_model\u001b[38;5;241m.\u001b[39mmodel(atoms, bond)\n",
      "File \u001b[1;32mc:\\Users\\Makss\\Documents\\Учёба\\Диплом\\NF_mol_gen\\utils.py:256\u001b[0m, in \u001b[0;36madj_to_smiles\u001b[1;34m(atoms, adj, num2atom, atom_valency)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madj_to_smiles\u001b[39m(atoms, adj, num2atom, atom_valency):\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# adj = _to_numpy_array(adj, gpu)\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# x = _to_numpy_array(x, gpu)\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     valid \u001b[38;5;241m=\u001b[39m [construct_mol(x_elem, adj_elem, num2atom, atom_valency)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    257\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m x_elem, adj_elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(atoms, adj)]\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid\n",
      "File \u001b[1;32mc:\\Users\\Makss\\Documents\\Учёба\\Диплом\\NF_mol_gen\\utils.py:256\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madj_to_smiles\u001b[39m(atoms, adj, num2atom, atom_valency):\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# adj = _to_numpy_array(adj, gpu)\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# x = _to_numpy_array(x, gpu)\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     valid \u001b[38;5;241m=\u001b[39m [\u001b[43mconstruct_mol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_elem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_elem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum2atom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matom_valency\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    257\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m x_elem, adj_elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(atoms, adj)]\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid\n",
      "File \u001b[1;32mc:\\Users\\Makss\\Documents\\Учёба\\Диплом\\NF_mol_gen\\utils.py:105\u001b[0m, in \u001b[0;36mconstruct_mol\u001b[1;34m(x, adj, num2atom, atom_valency)\u001b[0m\n\u001b[0;32m    103\u001b[0m atoms \u001b[38;5;241m=\u001b[39m atoms[atoms_exist]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m atom \u001b[38;5;129;01min\u001b[39;00m atoms:\n\u001b[1;32m--> 105\u001b[0m     mol\u001b[38;5;241m.\u001b[39mAddAtom(Chem\u001b[38;5;241m.\u001b[39mAtom(\u001b[43mnum2atom\u001b[49m\u001b[43m[\u001b[49m\u001b[43matom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# A (edge_type, num_node, num_node)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m adj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(adj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 9"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(\"Start at Time: {}\".format(ctime()))\n",
    "args = parser\n",
    "# configuration\n",
    "if args.dataset == 'polymer':\n",
    "    # polymer\n",
    "    num2atom = {0: 6, 1: 7, 2: 8, 3: 9, 4: 14, 5: 15, 6: 16}\n",
    "    atom_valency = {6: 4, 7: 3, 8: 2, 9: 1, 14: 4, 15: 3, 16: 2}\n",
    "else:\n",
    "    # zinc250k\n",
    "    num2atom = {0: 6, 1: 7, 2: 8, 3: 9, 4: 15, 5: 16, 6: 17, 7: 35, 8: 53}\n",
    "    atom_valency = {6: 4, 7: 3, 8: 2, 9: 1, 15: 3, 16: 2, 17: 1, 35: 1, 53: 1}\n",
    "\n",
    "args.strides = [2, 2, 2]\n",
    "data_path = os.path.join('./data_preprocessed', args.dataset)\n",
    "with open(os.path.join(data_path, 'config.txt'), 'r') as f:\n",
    "    data_config = eval(f.read())\n",
    "\n",
    "with open(\"./dataset/zinc250k/{}_idx.json\".format(args.split), \"r\") as f:\n",
    "    train_idx, valid_idx = json.load(f)\n",
    "dataset = PretrainDataset(\"./data_preprocessed/{}\".format(args.dataset), data_config, args)\n",
    "train_dataset = deepcopy(dataset)\n",
    "train_dataset._indices = train_idx\n",
    "valid_dataset = deepcopy(dataset)\n",
    "valid_dataset._indices = valid_idx\n",
    "\n",
    "if not os.path.exists(os.path.join(\"./data_preprocessed/{}\".format(args.dataset), 'zinc250k_property.csv')):\n",
    "    smiles_list = dataset.all_smiles\n",
    "    property_list = []\n",
    "    print(torch.multiprocessing.cpu_count())\n",
    "    with Pool(processes=torch.multiprocessing.cpu_count()) as pool:\n",
    "        iter = pool.imap(op.get_mol_property, smiles_list)\n",
    "        for idx, data in tqdm(enumerate(iter), total=len(smiles_list)):\n",
    "            property_list.append(data)\n",
    "    mol_property = np.array(property_list)\n",
    "    table = pd.DataFrame(mol_property, columns=['qed', 'plogp'])\n",
    "    table['smile'] = smiles_list\n",
    "    table.to_csv(os.path.join(\"./data_preprocessed/{}\".format(args.dataset), 'zinc250k_property.csv'), index=False)\n",
    "\n",
    "if args.hidden in ('', ','):\n",
    "    hidden = []\n",
    "else:\n",
    "    hidden = [int(d) for d in args.hidden.strip(',').split(',')]\n",
    "print('Hidden dim for output regression: ', hidden)\n",
    "\n",
    "if args.property_model_path is None:\n",
    "    property_list = op.load_property_csv(args.dataset, normalize=True)\n",
    "    mol_property = np.array(property_list) \n",
    "    train_dataset.is_mol_property = True\n",
    "    train_dataset.mol_property = mol_property\n",
    "    valid_dataset.is_mol_property = True\n",
    "    valid_dataset.mol_property = mol_property\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size,collate_fn=PretrainDataset.collate_fn, num_workers=args.num_workers, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size,collate_fn=PretrainDataset.collate_fn, num_workers=args.num_workers, drop_last=True)\n",
    "    print('Prepare data done! Time {:.2f} seconds'.format(time() - start))\n",
    "    property_model_path = os.path.join(args.model_dir, '{}_{}_{}_{}.pth'.format(args.property_name, args.split, args.dataset, args.ratio))\n",
    "    \n",
    "    model = MolHF(data_config, args).to(args.device)\n",
    "    op.initialize_from_checkpoint(model, args)\n",
    "    property_model = op.FlowProp(model, hidden).to(args.device)\n",
    "    property_model = op.fit_model(property_model, train_loader, valid_loader, args, property_model_path)   \n",
    "else:\n",
    "    print(\"Loading trained regression model for optimization\")\n",
    "    print('Prepare data done! Time {:.2f} seconds'.format(time() - start))\n",
    "    prop_list = op.load_property_csv(args.dataset, normalize=False)\n",
    "    train_prop = [prop_list[i] for i in train_idx]\n",
    "    test_prop = [prop_list[i] for i in valid_idx]\n",
    "    property_model_path = os.path.join(args.model_dir, args.property_model_path)\n",
    "    print(\"loading {} regression model from: {}\".format(args.property_name, property_model_path))\n",
    "    model = MolHF(data_config, args).to(args.device)\n",
    "    op.initialize_from_checkpoint(model, args)\n",
    "    property_model = op.FlowProp(model, hidden).to(args.device)\n",
    "    property_model.load_state_dict(torch.load(property_model_path, map_location=args.device))\n",
    "    print('Load model done! Time {:.2f} seconds'.format(time() - start))\n",
    "\n",
    "    property_model.eval()\n",
    "\n",
    "    if args.topscore:\n",
    "        print('Finding top score:')\n",
    "        op.find_top_score_smiles(property_model, test_prop if args.is_test_idx else train_prop, data_config, args)\n",
    "\n",
    "    if args.consopt:\n",
    "        print('Constrained optimization:')\n",
    "        op.constrain_optimization_smiles(property_model, test_prop if args.is_test_idx else train_prop, data_config, args)\n",
    "        \n",
    "    print('Total Time {:.2f} seconds'.format(time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_ml310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
