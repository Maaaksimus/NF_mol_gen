{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('idx.json', 'w') as f:\n",
    "    json.dump(train_test_split(list(range(1,101)), test_size=0.2, random_state=42), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 5]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,0,0,0,1,1])\n",
    "np.nonzero(a)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([56,\n",
       "  89,\n",
       "  27,\n",
       "  43,\n",
       "  70,\n",
       "  16,\n",
       "  41,\n",
       "  97,\n",
       "  10,\n",
       "  73,\n",
       "  12,\n",
       "  48,\n",
       "  86,\n",
       "  29,\n",
       "  94,\n",
       "  6,\n",
       "  67,\n",
       "  66,\n",
       "  36,\n",
       "  17,\n",
       "  50,\n",
       "  35,\n",
       "  8,\n",
       "  96,\n",
       "  28,\n",
       "  20,\n",
       "  82,\n",
       "  26,\n",
       "  63,\n",
       "  14,\n",
       "  25,\n",
       "  4,\n",
       "  18,\n",
       "  39,\n",
       "  9,\n",
       "  79,\n",
       "  7,\n",
       "  65,\n",
       "  37,\n",
       "  90,\n",
       "  57,\n",
       "  100,\n",
       "  55,\n",
       "  44,\n",
       "  51,\n",
       "  68,\n",
       "  47,\n",
       "  69,\n",
       "  62,\n",
       "  98,\n",
       "  80,\n",
       "  42,\n",
       "  59,\n",
       "  49,\n",
       "  99,\n",
       "  58,\n",
       "  76,\n",
       "  33,\n",
       "  95,\n",
       "  60,\n",
       "  64,\n",
       "  85,\n",
       "  38,\n",
       "  30,\n",
       "  2,\n",
       "  53,\n",
       "  22,\n",
       "  3,\n",
       "  24,\n",
       "  88,\n",
       "  92,\n",
       "  75,\n",
       "  87,\n",
       "  83,\n",
       "  21,\n",
       "  61,\n",
       "  72,\n",
       "  15,\n",
       "  93,\n",
       "  52],\n",
       " [84,\n",
       "  54,\n",
       "  71,\n",
       "  46,\n",
       "  45,\n",
       "  40,\n",
       "  23,\n",
       "  81,\n",
       "  11,\n",
       "  1,\n",
       "  19,\n",
       "  31,\n",
       "  74,\n",
       "  34,\n",
       "  91,\n",
       "  5,\n",
       "  77,\n",
       "  78,\n",
       "  13,\n",
       "  32])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('idx.json', 'r') as f:\n",
    "    tr, tst = json.load(f)\n",
    "\n",
    "tr, tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка из  ./docking/DS_data/0k/\n",
      "Загрузка из  ./docking/DS_data/25k/\n",
      "Загрузка из  ./docking/DS_data/50k/\n",
      "Загрузка из  ./docking/DS_data/75k/\n",
      "Загрузка из  ./docking/DS_data/100k/\n",
      "Alarm:  ./docking/DS_data/100k/\n",
      "Загрузка из  ./docking/DS_data/125k/\n",
      "Загрузка из  ./docking/DS_data/150k/\n",
      "Загрузка из  ./docking/DS_data/175k/\n",
      "Загрузка из  ./docking/DS_data/200k/\n",
      "Загрузка из  ./docking/DS_data/225k/\n",
      "Alarm:  docking_scores_249000-249455.npy\n"
     ]
    }
   ],
   "source": [
    "path = './docking/DS_data/'\n",
    "files = sorted(os.listdir(path))\n",
    "a = np.empty(0, dtype=float)\n",
    "\n",
    "for i in range(10):\n",
    "    loc_path = path + f'{i * 25}k/'\n",
    "    print('Загрузка из ', loc_path)\n",
    "    files = sorted(os.listdir(loc_path))\n",
    "    if len(files) < 25:\n",
    "        print('Alarm: ', loc_path)\n",
    "    for file in files:\n",
    "        a_new = np.load(loc_path + file, allow_pickle=True)\n",
    "        a = np.concat([a, a_new])\n",
    "        if a_new.shape[0] != 1000:\n",
    "            print('Alarm: ', file)\n",
    "\n",
    "a.dump('docking_scores_all.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0] - len(smiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.sascorer import calculateScore\n",
    "\n",
    "file_path = os.path.join('./dataset/zinc250k/zinc250k.smi')\n",
    "fp = open(file_path, 'r')\n",
    "smiles_list = [smiles.strip() for smiles in fp]\n",
    "\n",
    "sas = lambda sml: calculateScore(Chem.MolFromSmiles(sml))\n",
    "sas_vec = np.vectorize(sas)\n",
    "\n",
    "def tanimoto(sml):\n",
    "    \n",
    "    mol_dmnp = Chem.MolFromSmiles('CC1CCC(C2=C1C=CC(=C2)C)C(C)CCC(=O)O')\n",
    "    fp_dmnp = Chem.AllChem.GetMorganFingerprint(mol_dmnp, 2)\n",
    "\n",
    "    mol_sml = Chem.MolFromSmiles(sml)\n",
    "    fp_sml = Chem.AllChem.GetMorganFingerprint(mol_sml, 2) # здесь возможно возникает то самое предупреждение с MorganFingerprint\n",
    "    \n",
    "    return DataStructs.TanimotoSimilarity(fp_dmnp, fp_sml) # здесь вставить свой dist\n",
    "\n",
    "tanimoto_vec = np.vectorize(tanimoto)\n",
    "\n",
    "ds = ...\n",
    "sa = sas_vec(smiles_list)\n",
    "td = tanimoto_vec(smiles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = pd.DataFrame({'SMILES': np.array(smiles_list), 'DS': ds, 'SA': sa, 'TD': td})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.to_csv('tmp_docking_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.6, -8.4, -8.9, -8.1, -7.5, -4.8, -6.2, -8.4, -8.4, -6.4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('docking_scores_0-9.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = np.load('docking_scores.npy', allow_pickle=True)\n",
    "ds[ds != 0][797:798].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У train №797 DS -9.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes done\n",
      "Bonds done\n"
     ]
    }
   ],
   "source": [
    "X = np.load('./data_preprocessed/zinc250k/node_features.npy')\n",
    "print('Nodes done')\n",
    "A = np.load('./data_preprocessed/zinc250k/adj_features.npy')\n",
    "print('Bonds done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_sizes = np.load('./data_preprocessed/zinc1500k/mol_sizes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMNP_mol = Chem.MolFromPDBFile(\"./docking/294-BD_AD_receptor_ligand_140.988_160.730_-16.038/294-BD_AD_receptor_ligand_140.988_160.730_-16.038.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC1CCC2C(C)CCC(C(C)CCC(O)O)C2C1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMNP_smiles = Chem.MolToSmiles(DMNP_mol)\n",
    "DMNP_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()  # Текущая рабочая директория\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "file_path = os.path.join(parent_dir, 'title.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('q:\\\\Учеба\\\\Универ\\\\6 курс\\\\Диплом\\\\NF_mol_gen',\n",
       " 'q:\\\\Учеба\\\\Универ\\\\6 курс\\\\Диплом',\n",
       " 'q:\\\\Учеба\\\\Универ\\\\6 курс\\\\Диплом\\\\title.txt')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir, parent_dir, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import subprocess\n",
    "\n",
    "# protein = Chem.MolFromPDBFile(\"./docking/294-BD_AD_receptor_ligand_140.988_160.730_-16.038/receptor.pdb\")\n",
    "# Chem.MolToPDBFile(protein, \"receptor_rdkit.pdbqt\")\n",
    "\n",
    "def pdb_to_pdbqt_rdkit(input_pdb, output_pdbqt):\n",
    "    \"\"\"\n",
    "    Конвертирует PDB в PDBQT с помощью RDKit (подготовка) и Open Babel (финальная конвертация).\n",
    "    \n",
    "    Параметры:\n",
    "        input_pdb (str): Путь к входному PDB-файлу.\n",
    "        output_pdbqt (str): Путь для сохранения PDBQT-файла.\n",
    "    \"\"\"\n",
    "    # 1. Загрузка PDB в RDKit\n",
    "    print(1)\n",
    "    mol = Chem.MolFromPDBFile(input_pdb, removeHs=False)\n",
    "    if mol is None:\n",
    "        raise ValueError(\"Не удалось загрузить PDB-файл. Проверьте его целостность.\")\n",
    "\n",
    "    # 2. Добавление водородов (если их нет)\n",
    "    print(2)\n",
    "    mol = Chem.AddHs(mol, addCoords=True)\n",
    "\n",
    "    # 3. Оптимизация геометрии (MMFF94 или UFF)\n",
    "    print(3)\n",
    "    try:\n",
    "        AllChem.MMFFOptimizeMolecule(mol)  # MMFF94\n",
    "    except:\n",
    "        AllChem.UFFOptimizeMolecule(mol)  # Fallback на UFF\n",
    "\n",
    "    # 4. Сохраняем во временный PDB-файл (RDKit не поддерживает PDBQT)\n",
    "    print(4)\n",
    "    temp_pdb = \"temp_rdkit.pdb\"\n",
    "    Chem.MolToPDBFile(mol, temp_pdb)\n",
    "\n",
    "    # 5. Конвертируем PDB → PDBQT через Open Babel\n",
    "    print(5)\n",
    "    obabel_cmd = f\"obabel {temp_pdb} -O {output_pdbqt} -xh --partialcharge gasteiger\"\n",
    "    subprocess.run(obabel_cmd, shell=True, check=True)\n",
    "\n",
    "    print(f\"Файл сохранен: {output_pdbqt}\")\n",
    "\n",
    "# Пример использования\n",
    "# pdb_to_pdbqt_rdkit(\"input.pdb\", \"output.pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Файл сохранен: ./docking/receptor_auto.pdbqt\n"
     ]
    }
   ],
   "source": [
    "pdb_to_pdbqt_rdkit('./docking/294-BD_AD_receptor_ligand_140.988_160.730_-16.038/receptor.pdb', './docking/receptor_auto.pdbqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Zinc_Processor, SmilesPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SmilesPreprocessor(add_Hs=False, kekulize=True, max_atoms=38, max_size=40)\n",
    "x, A, sz, _ = sp.process('CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./docking/Марк/zinc_DS/2025-04-12_16-29-13/docking_scores_0-9.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sl:  ['CC1CCC(C2=C1C=CC(=C2)C)C(C)CCC(=O)O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of valid molecule in dataset: 1\n",
      "try to save\n",
      "./my_scripts\n",
      "saving node/adj feature...\n",
      "shape of node feature: (1, 50)\n",
      "shape of adj features: (1, 3, 50, 50)\n",
      "shape of mol sizes: (1,)\n",
      "save config\n",
      "saving config...\n",
      "{'atom_list': [6, 7, 8, 9, 15, 16, 17, 35, 53, 0], 'node_dim': 10, 'max_size': 50, 'bond_dim': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zp = Zinc_Processor('DMNP_read.txt', './my_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.8, -8. , -3.7, -6.5, -8.2, -7.1, -6.8, -6.8, -6.6, -7. ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concat([np.empty(0), np.load(path + file, allow_pickle=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./docking/DS_data/25k/small/docking_scores_27630-27639.npy', allow_pickle=True)[:1000] == np.load('./docking/DS_data/25k/small/rdy/docking_scores_27000-27999.npy', allow_pickle=True)[630:640]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of  docking_scores_25000-25999.npy :  1000\n",
      "Size of  docking_scores_26000-26999.npy :  1000\n",
      "Size of  docking_scores_27000-27999.npy :  1000\n",
      "Size of  docking_scores_28000-28999.npy :  1000\n",
      "Size of  docking_scores_29000-29999.npy :  1000\n",
      "Size of  docking_scores_30000-30999.npy :  1000\n",
      "Size of  docking_scores_31000-31999.npy :  1000\n",
      "Size of  docking_scores_32000-32999.npy :  1000\n",
      "Size of  docking_scores_33000-33999.npy :  1000\n",
      "Size of  docking_scores_34000-34999.npy :  1000\n",
      "Size of  docking_scores_35000-35999.npy :  1000\n",
      "Size of  docking_scores_36000-36999.npy :  1000\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './docking/DS_data/25k/small/rdy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files):\n\u001b[1;32m----> 5\u001b[0m     a_new \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcat([a, a_new])\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Makss\\anaconda3\\envs\\cuda_ml310\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:455\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    456\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './docking/DS_data/25k/small/rdy'"
     ]
    }
   ],
   "source": [
    "path = './docking/DS_data/25k/small/'\n",
    "files = sorted(os.listdir(path))\n",
    "a = np.empty(0, dtype=float)\n",
    "for i, file in enumerate(files):\n",
    "    a_new = np.load(path + file, allow_pickle=True)\n",
    "    a = np.concat([a, a_new])\n",
    "    if (i + 1) % 100 == 0:\n",
    "        file_name = f'docking_scores_{25000 + (i - 99) * 10}-{25000 + i * 10 + 9}.npy'\n",
    "        a.dump(path + 'rdy/' + file_name)\n",
    "        print('Size of ', file_name, ': ', a.shape[0])\n",
    "        a = np.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    with open('mse.txt', 'a') as f:\n",
    "        f.write(f'{i},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterCatalogEntry> already registered; second conversion method ignored.\n"
     ]
    }
   ],
   "source": [
    "from utils import valid_mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moses\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = moses.get_dataset('train')\n",
    "test = moses.get_dataset('test')\n",
    "test_scaffolds = moses.get_dataset('test_scaffolds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from moses import CharVocab, StringDataset\n",
    "\n",
    "train = moses.get_dataset('train')\n",
    "vocab = CharVocab.from_data(train)\n",
    "train_dataset = StringDataset(vocab, train)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=512,\n",
    "    shuffle=True, collate_fn=train_dataset.default_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\n",
       "1              CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1\n",
       "2               Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO\n",
       "3                  Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C\n",
       "4                    CC1Oc2ccc(Cl)cc2N(CC(O)CO)C1=O\n",
       "                             ...                   \n",
       "1584658                        N#Cc1c(Br)cnc(N)c1Br\n",
       "1584659          COC(=O)c1cc(CNC(=O)OC(C)(C)C)ccc1C\n",
       "1584660                      NC(=O)c1ccc2ccccc2c1Br\n",
       "1584661    CC(=O)Nc1cccc(-c2nc3cc(C)ccc3[nH]c2=O)c1\n",
       "1584662     CC(NC(=O)OC(C)(C)C)c1nc(CO)nn1Cc1ccccc1\n",
       "Length: 1584663, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train)#.to_csv('zinc1500K.smi', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512]) torch.Size([50, 512]) 512\n",
      "torch.Size([49, 512]) torch.Size([49, 512]) 512\n",
      "torch.Size([52, 512]) torch.Size([52, 512]) 512\n"
     ]
    }
   ],
   "source": [
    "for i, (with_bos, with_eos, lengths) in enumerate(train_dataloader):\n",
    "    print(with_bos.shape, with_eos.shape, len(lengths))\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " moses.utils.CharVocab,\n",
       " moses.utils.StringDataset,\n",
       " torch.utils.data.dataloader.DataLoader)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train), type(vocab), type(train_dataset), type(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584663,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from moses import CharVocab, StringDataset\n",
    "\n",
    "train = moses.get_dataset('train')\n",
    "vocab = CharVocab.from_data(train)\n",
    "train_dataset = StringDataset(vocab, train)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=512,\n",
    "    shuffle=True, collate_fn=train_dataset.default_collate\n",
    ")\n",
    "\n",
    "for with_bos, with_eos, lengths in train_dataloader:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs import molecular_metrics as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5149307387756714"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.MolecularMetrics._compute_SAS(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cc1c(NC(=O)CSc2nc3sc4c(c3c(=O)[nH]2)CCCC4)c(=O)n(-c2ccccc2)n1C'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_list[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA Score для CC1CCC(C2=C1C=CC(=C2)C)C(C)CCC(=O)O: 3.3559737244164882\n",
      "SA Score для Cc1c(NC(=O)CSc2nc3sc4c(c3c(=O)[nH]2)CCCC4)c(=O)n(-c2ccccc2)n1C: 2.62217770660925\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from envs.sascorer import calculateScore\n",
    "\n",
    "smiles1 = \"CC1CCC(C2=C1C=CC(=C2)C)C(C)CCC(=O)O\"\n",
    "mol1 = Chem.MolFromSmiles(smiles1)\n",
    "sa_score1 = calculateScore(mol1)\n",
    "print(f\"SA Score для {smiles1}: {sa_score1}\")\n",
    "\n",
    "smiles2 = \"Cc1c(NC(=O)CSc2nc3sc4c(c3c(=O)[nH]2)CCCC4)c(=O)n(-c2ccccc2)n1C\"\n",
    "mol2 = Chem.MolFromSmiles(smiles2)\n",
    "sa_score2 = calculateScore(mol2)\n",
    "print(f\"SA Score для {smiles2}: {sa_score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Танимото схожесть: 0.13178294573643412\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import rdkit\n",
    "import rdkit.Chem\n",
    "\n",
    "fp1 = AllChem.GetMorganFingerprint(mol1, 2)\n",
    "fp2 = AllChem.GetMorganFingerprint(mol2, 2)\n",
    "\n",
    "sim = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "print('Танимото схожесть: {}'.format(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('./dataset/zinc250k/zinc250k.smi', 'r')\n",
    "smiles_list = [smiles.strip() for smiles in fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x21c8a07cf90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mol(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1ccccc1\n"
     ]
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('C1=CC=CC=C1')\n",
    "sml = Chem.MolToSmiles(mol)\n",
    "print(sml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Пример SMILES\n",
    "smiles = 'CC(=O)O'  # бензол\n",
    "\n",
    "# Создание молекулы из SMILES\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Рисование молекулы и сохранение изображения\n",
    "img = Draw.MolToFile(mol, 'molecule.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_ml39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
